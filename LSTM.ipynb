{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from readfile import readfile\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDir = \"/home/qiz103/PA4\"\n",
    "#torch.manual_seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainList(filePath,oneHotDict):\n",
    "    songList = []\n",
    "    f = open(filePath)\n",
    "    for line in f:\n",
    "        if line == \"<start>\\n\":\n",
    "            song = []\n",
    "            song.append(oneHotDict[\"~~\"])\n",
    "        elif line == \"<end>\\n\":\n",
    "            song.append(oneHotDict[\"~~~\"])\n",
    "            songList.append(song)\n",
    "        else: \n",
    "            for char in line:\n",
    "                song.append(oneHotDict[char])\n",
    "                \n",
    "    return songList\n",
    "            \n",
    "def chunkListHelper(song):\n",
    "    chunkList = []\n",
    "    for idx in range(math.floor(len(song) / 100)):\n",
    "        chunk = song[(idx*100):((idx + 1)*100)]\n",
    "        if len(chunk)!= 0:\n",
    "            chunkList.append(chunk)\n",
    "    chunk = song[(math.floor(len(song) / 100)*100):len(song)]\n",
    "    if len(chunk)!= 0:\n",
    "        chunkList.append(chunk)\n",
    "    \n",
    "    resultList = []\n",
    "    for chunk in chunkList:\n",
    "        result = np.empty([len(chunk),1,96])\n",
    "        for seqIdx,seq in enumerate(chunk):\n",
    "            result[seqIdx][0] = seq\n",
    "        \n",
    "        resultList.append(result)\n",
    "            \n",
    "            \n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "<class 'numpy.ndarray'>\n",
      "96\n",
      "what is the type of note float32\n"
     ]
    }
   ],
   "source": [
    "filePath = fileDir + \"/train.txt\"\n",
    "valPath = fileDir + \"/val.txt\"\n",
    "testPath = fileDir + \"/test.txt\"\n",
    "fileReader = readfile()\n",
    "oneHotDict = fileReader.returnTheDict(filePath)\n",
    "print(len(oneHotDict))\n",
    "songList = generateTrainList(filePath,oneHotDict)\n",
    "print(type(songList[0][0]))\n",
    "print(len(songList[0][0]))\n",
    "print(\"what is the type of note\", songList[0][0].dtype)\n",
    "valList = generateTrainList(valPath,oneHotDict)\n",
    "testList = generateTrainList(testPath,oneHotDict)\n",
    "random.shuffle(songList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCustom(data.Dataset):\n",
    "    def __init__(self,songList):\n",
    "        self.songList = songList\n",
    "    def __len__(self):\n",
    "        return len(self.songList)\n",
    "    def __getitem__(self,index):\n",
    "        return self.songList[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing part of Dataset generator \n",
    "datasetCustom = DatasetCustom(songList)\n",
    "trainloader = torch.utils.data.DataLoader(datasetCustom, batch_size=1,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMcustomize(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,layerNum,dropout):\n",
    "        super(LSTMcustomize,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size = inputSize,hidden_size = hiddenSize,num_layers = layerNum,dropout = dropout)\n",
    "        self.to_output = nn.Linear(hiddenSize,inputSize)\n",
    "        #self.to_act = nn.Softmax()\n",
    "        self.h0 = torch.zeros(layerNum,1,hiddenSize)\n",
    "        self.c0 = torch.zeros(layerNum,1,hiddenSize)\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.inputSize = inputSize\n",
    "        self.layerNum = layerNum\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        self.h0 = self.h0.requires_grad_().to(computing_device)\n",
    "        self.c0 = self.c0.requires_grad_().to(computing_device)\n",
    "        #print(\"input is cuda\",input.is_cuda)\n",
    "        #print(\"is ho  cuda\",self.h0.is_cuda)\n",
    "        #print(\"is c0 cuda\", self.c0.is_cuda)\n",
    "        self.h0 = self.h0.float()\n",
    "        self.c0 = self.c0.float()\n",
    "        input = input.float()\n",
    "        #print(\"type check\", input.dtype)\n",
    "        #print(\"type of h0 is \",self.h0.dtype)\n",
    "        #print(\"type of c0 is \",self.c0.dtype)\n",
    "        #self.h0.double()\n",
    "        #self.c0.double()\n",
    "        #input.double()\n",
    "        output,(hn,cn) = self.lstm(input,(self.h0.detach(),self.c0.detach()))\n",
    "        self.h0 = hn\n",
    "        self.c0 = cn\n",
    "        linearOut = self.to_output(output.view(-1,self.hiddenSize))\n",
    "        #result = self.to_act(linearOut)\n",
    "        return linearOut\n",
    "    \n",
    "    def setHiddenCell(self,h0,c0):\n",
    "        self.h0 = h0\n",
    "        self.c0 = c0\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMcustomize(\n",
      "  (lstm): LSTM(96, 175)\n",
      "  (to_output): Linear(in_features=175, out_features=96, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layerNum = 1\n",
    "hiddenSize = 175\n",
    "#lstm = LSTMcustomize(inputSize = 95 ,hiddenSize = 100,layerNum = 1,dropout = 0)\n",
    "lstm = LSTMcustomize(inputSize = 96 ,hiddenSize = hiddenSize,layerNum = layerNum,dropout = 0).to(computing_device)\n",
    "print(lstm)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lstm.parameters(),lr = 0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainingLoss = []\n",
    "validationLoss = []\n",
    "testLoss = []\n",
    "earlyStopPatience = 5\n",
    "prevLoss = 5\n",
    "counter = 0\n",
    "for epoch in range(600):\n",
    "    print(\"epoch is \",epoch)\n",
    "    trainSumEachEpoch = 0\n",
    "    trainchunkSum = 0\n",
    "    valSumEachEpoch = 0\n",
    "    valchunkSum = 0\n",
    "    for trainSong in trainloader:\n",
    "        chunkList = chunkListHelper(trainSong)\n",
    "        for chunk in chunkList:\n",
    "            #print(\"batch idx\",trainchunkSum)\n",
    "            #print(\"chunk is\",chunk.shape)\n",
    "            #print(\"train song is \",len(trainSong))\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            #print(\"target is\", target)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            lstm.zero_grad()\n",
    "            predict = lstm(chunkTensor)\n",
    "            #print(\"target tensor is\",targetTensor)\n",
    "            #print(\"target shape is \",targetTensor.shape)\n",
    "            #print(\"output shape is \",predict.shape)\n",
    "            targetTensor = targetTensor.type(torch.LongTensor)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            #print(\"batch is %s loss is %s\",(trainchunkSum,loss))\n",
    "            trainSumEachEpoch += loss\n",
    "            trainchunkSum += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        lstm.setHiddenCell(h0 = torch.zeros(layerNum,1,hiddenSize),c0 = torch.zeros(layerNum,1,hiddenSize))\n",
    "        \n",
    "    \n",
    "    #save model\n",
    "    trainSumEachEpoch = trainSumEachEpoch / trainchunkSum\n",
    "    trainingLoss.append(trainSumEachEpoch.item())\n",
    "    savePath =\"./\"+\"%depoch%smodel.pt\"%(epoch,\"best\")\n",
    "    torch.save(lstm, fileDir+\"/\"+savePath)\n",
    "    print(\"training error is\",trainSumEachEpoch.item())\n",
    "    print(\"model saved\")\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for valSong in valList:\n",
    "            chunkList = chunkListHelper(valSong)\n",
    "            for chunk in chunkList:\n",
    "                target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "                target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "                target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "                target = np.squeeze(target, axis=1)\n",
    "                target = np.argmax(target,axis = 1)\n",
    "                chunkTensor = torch.from_numpy(chunk)\n",
    "                targetTensor = torch.from_numpy(target)\n",
    "                targetTensor = targetTensor.long()\n",
    "                chunkTensor = chunkTensor.to(computing_device)\n",
    "                targetTensor = targetTensor.to(computing_device)\n",
    "                predict = lstm(chunkTensor)\n",
    "                loss = loss_function(predict,targetTensor)\n",
    "                valSumEachEpoch+=loss\n",
    "                valchunkSum+=1\n",
    "\n",
    "        valSumEachEpoch = valSumEachEpoch / valchunkSum\n",
    "        validationLoss.append(valSumEachEpoch.item())\n",
    "        print(\"validation error is\", valSumEachEpoch.item())\n",
    "        \n",
    "        # implement early stop\n",
    "        if valSumEachEpoch.item() >= prevLoss:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "        if counter > earlyStopPatience:\n",
    "            print(\"stop training for exceeding patience \")\n",
    "            break\n",
    "        #print(\"epoch is )\n",
    "        prevLoss = valSumEachEpoch.item()\n",
    "        #print(\"trainging in epoch end\")\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report metrics\n",
    "modelPath = \"15epochbestmodel.pt\"\n",
    "lstm = torch.load(modelPath)\n",
    "valchunkSum = 0\n",
    "valSumEachEpoch = 0\n",
    "with torch.no_grad():\n",
    "    for valSong in valList:\n",
    "        chunkList = chunkListHelper(valSong)\n",
    "        for chunk in chunkList:\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.long()\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            predict = lstm(chunkTensor)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            valSumEachEpoch+=loss\n",
    "            valchunkSum+=1\n",
    "\n",
    "    valSumEachEpoch = valSumEachEpoch / valchunkSum\n",
    "    print(\"validation loss is \",valSumEachEpoch.item())\n",
    "\n",
    "testchunkSum = 0\n",
    "testSumEachEpoch = 0\n",
    "with torch.no_grad():\n",
    "    for testSong in testList:\n",
    "        chunkList = chunkListHelper(testSong)\n",
    "        for chunk in chunkList:\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.long()\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            predict = lstm(chunkTensor)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            testSumEachEpoch+=loss\n",
    "            testchunkSum+=1\n",
    "\n",
    "    testSumEachEpoch = testSumEachEpoch / testchunkSum\n",
    "    print(\"test loss is \",testSumEachEpoch.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training validation loss using SGD with learning rate 0.05, momentum 0.9, 200 neuron and 2 hidden layer')\n",
    "xAxis = np.arange(0,30)\n",
    "plt.plot(xAxis,trainingLoss[0:30],label = 'training loss')\n",
    "plt.plot(xAxis,validationLoss[0:30], label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(fileDir + \"test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([0.25, 0.25, 0.25, 0.25], dtype=torch.float) # create a tensor of weights\n",
    "a = torch.multinomial(weights, 1)\n",
    "a = a.numpy()\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char is  X\n",
      "char is  :\n",
      "char is  5\n",
      "char is  \n",
      "\n",
      "char is  T\n",
      "char is  :\n",
      "char is  L\n",
      "char is  e\n",
      "char is   \n",
      "char is  D\n",
      "char is  o\n",
      "char is  n\n",
      "char is  n\n",
      "char is  o\n",
      "char is  r\n",
      "char is  g\n",
      "char is  i\n",
      "char is  n\n",
      "char is  e\n",
      "char is  \n",
      "\n",
      "char is  '\n",
      "char is  :\n",
      "char is  T\n",
      "char is  r\n",
      "char is  a\n",
      "char is  n\n",
      "char is  s\n",
      "char is  c\n",
      "char is  r\n",
      "char is  i\n",
      "char is  t\n",
      "char is   \n",
      "char is  e\n",
      "char is  a\n",
      "char is  r\n",
      "char is   \n",
      "char is  M\n",
      "char is  i\n",
      "char is  c\n",
      "char is  h\n",
      "char is  e\n",
      "char is  l\n",
      "char is   \n",
      "char is  B\n",
      "char is  e\n",
      "char is  r\n",
      "char is  l\n",
      "char is  o\n",
      "char is  n\n",
      "char is   \n",
      "char is  2\n",
      "char is  0\n",
      "char is  0\n",
      "char is  6\n",
      "char is  -\n",
      "char is  2\n",
      "char is  \n",
      "\n",
      "char is  M\n",
      "char is  :\n",
      "char is  2\n",
      "char is  |\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  1\n",
      "char is  /\n",
      "char is  8\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  1\n",
      "char is  /\n",
      "char is  4\n",
      "char is  =\n",
      "char is  1\n",
      "char is  2\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  \n",
      "\n",
      "char is  d\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  !\n",
      "char is  f\n",
      "char is  e\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  f\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  !\n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is  )\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  B\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  f\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is  c\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  4\n",
      "char is   \n",
      "char is  :\n",
      "char is  |\n",
      "char is  2\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  B\n",
      "char is  c\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  3\n",
      "char is  c\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  3\n",
      "char is  /\n",
      "char is  2\n",
      "char is  A\n",
      "char is  /\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  F\n",
      "char is  2\n",
      "char is   \n",
      "char is  G\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is  )\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  !\n",
      "char is  F\n",
      "char is  !\n",
      "char is  F\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  2\n",
      "char is  f\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  )\n",
      "char is  f\n",
      "char is  2\n",
      "char is  e\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  4\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  4\n",
      "char is  f\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  B\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  3\n",
      "char is  c\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  )\n",
      "char is  f\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  4\n",
      "char is  -\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is  c\n",
      "char is  !\n",
      "char is  c\n",
      "char is  e\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  !\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  d\n",
      "char is  !\n",
      "char is  G\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  F\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is  c\n",
      "char is  d\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  )\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  3\n",
      "char is  d\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  2\n",
      "char is  g\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  g\n",
      "char is  2\n",
      "char is  )\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  2\n",
      "char is  d\n",
      "char is  B\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  g\n",
      "char is  2\n",
      "char is  f\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  e\n",
      "char is  !\n",
      "char is  f\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  f\n",
      "char is  2\n",
      "char is  e\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  d\n",
      "char is  c\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  d\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  B\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char is  2\n",
      "char is  )\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  F\n",
      "char is  2\n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  f\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  e\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  d\n",
      "char is  4\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  !\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  A\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  c\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is  F\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  c\n",
      "char is  2\n",
      "char is  d\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is  F\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  F\n",
      "char is  !\n",
      "char is  D\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is  z\n",
      "char is  2\n",
      "char is   \n",
      "char is  F\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  A\n",
      "char is  2\n",
      "char is  F\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is  )\n",
      "char is  G\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  !\n",
      "char is  F\n",
      "char is   \n",
      "char is  G\n",
      "char is  !\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  G\n",
      "char is  2\n",
      "char is  F\n"
     ]
    }
   ],
   "source": [
    "musicName = \"/experimentMusic.txt\"\n",
    "if os.path.exists(fileDir+musicName):\n",
    "    os.remove(fileDir+musicName)\n",
    "f = open(fileDir+musicName,\"w\")\n",
    "modelPath = \"15epochbestmodel.pt\"\n",
    "primeLength = 1\n",
    "songIndex = 255\n",
    "musicString = \"\"\n",
    "temperature = 0.5\n",
    "length = 1000\n",
    "\n",
    "prime = songList[songIndex][0:primeLength]\n",
    "for idx in range(primeLength):\n",
    "    char = fileReader.noteList[np.argmax(songList[songIndex][idx])]\n",
    "    if char == \"~~\":\n",
    "        char = \"<start>\\n\"\n",
    "    \n",
    "    if char == \"~~~\":\n",
    "        char = \"<end>\\n\"\n",
    "        \n",
    "    musicString += char\n",
    "lstm = torch.load(modelPath)\n",
    "with torch.no_grad():\n",
    "    inputChunk = np.empty([len(prime),1,96])\n",
    "    for seqIdx,seq in enumerate(prime):\n",
    "        inputChunk[seqIdx][0] = seq\n",
    "    inputChunk = torch.from_numpy(inputChunk)\n",
    "    inputTensor = inputChunk.to(computing_device)\n",
    "    predict = lstm(inputTensor)\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    predict = softmax(predict / temperature)\n",
    "    prevOutput = predict.cpu().detach().numpy()\n",
    "    temp = predict[predict.shape[0]-1]\n",
    "    prevOutputIndex = torch.multinomial(temp, 1)\n",
    "    prevOutputIndex = prevOutputIndex.cpu().numpy()\n",
    "    prevOutputIndex = prevOutputIndex[0]\n",
    "    prevOutput = fileReader.noteList[prevOutputIndex]\n",
    "\n",
    "    nextInput = np.empty([1,1,96])\n",
    "    prevOutput = \"~~\"\n",
    "    nextInput[0][0] = oneHotDict[prevOutput]\n",
    "    nextInput = torch.from_numpy(nextInput)\n",
    "    nextInput = nextInput.to(computing_device)\n",
    "    \n",
    "    for eachidx in range(length):\n",
    "        prevOutput = lstm(nextInput)\n",
    "        prevOutput = softmax(prevOutput / temperature)\n",
    "        prevOutputIndex = torch.multinomial(prevOutput[0], 1)\n",
    "        prevOutputIndex = prevOutputIndex.cpu().numpy()\n",
    "        prevOutputIndex = prevOutputIndex[0]\n",
    "        prevOutput = prevOutput.cpu().detach().numpy()\n",
    "        prevOutput = fileReader.noteList[prevOutputIndex]\n",
    "        if prevOutput != \"!!!!\":\n",
    "            if prevOutput == \"~~\":\n",
    "                musicString +=\"\"\n",
    "            elif prevOutput == \"~~~\":\n",
    "                musicString +=\"\"\n",
    "            elif prevOutput == \"\\n\":\n",
    "                musicString +=\"\"\n",
    "            else:\n",
    "                musicString += prevOutput\n",
    "        \n",
    "        nextInput = np.empty([1,1,96])\n",
    "        nextInput[0][0] = oneHotDict[prevOutput]\n",
    "        nextInput = torch.from_numpy(nextInput)\n",
    "        nextInput = nextInput.to(computing_device)\n",
    "        \n",
    "        \n",
    "        print(\"char is \",prevOutput)\n",
    "                \n",
    "\n",
    "musicString += \"\\n\"\n",
    "musicString += \"<end>\\n\"\n",
    "f.write(musicString)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vaRNN(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,layerNum,dropout,nonlinearity):\n",
    "        super(vaRNN,self).__init__()\n",
    "        self.varnn = nn.RNN(input_size = inputSize,hidden_size = hiddenSize,num_layers = layerNum, nonlinearity = nonlinearity, dropout = dropout)\n",
    "        self.to_output = nn.Linear(hiddenSize,inputSize)\n",
    "        #self.to_act = nn.Softmax()\n",
    "        self.h0 = torch.zeros(layerNum,1,hiddenSize)\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.inputSize = inputSize\n",
    "        self.layerNum = layerNum\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        self.h0 = self.h0.requires_grad_().to(computing_device)\n",
    "        #print(\"input is cuda\",input.is_cuda)\n",
    "        #print(\"is ho  cuda\",self.h0.is_cuda)\n",
    "        #print(\"is c0 cuda\", self.c0.is_cuda)\n",
    "        self.h0 = self.h0.float()\n",
    "        input = input.float()\n",
    "        #print(\"type check\", input.dtype)\n",
    "        #print(\"type of h0 is \",self.h0.dtype)\n",
    "        #print(\"type of c0 is \",self.c0.dtype)\n",
    "        #self.h0.double()\n",
    "        #self.c0.double()\n",
    "        #input.double()\n",
    "        output,hn = self.varnn(input,self.h0.detach())\n",
    "        self.h0 = hn\n",
    "        linearOut = self.to_output(output.view(-1,self.hiddenSize))\n",
    "        #result = self.to_act(linearOut)\n",
    "        return linearOut\n",
    "    \n",
    "    def setHiddenCell(self,h0):\n",
    "        self.h0 = h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerNum = 1\n",
    "hiddenSize = 175\n",
    "#lstm = LSTMcustomize(inputSize = 95 ,hiddenSize = 100,layerNum = 1,dropout = 0)\n",
    "rnn = vaRNN(inputSize = 96 ,hiddenSize = hiddenSize,layerNum = layerNum,nonlinearity = 'tanh',dropout = 0).to(computing_device)\n",
    "print(rnn)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(rnn.parameters(),lr = 0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLoss = []\n",
    "validationLoss = []\n",
    "testLoss = []\n",
    "earlyStopPatience = 5\n",
    "prevLoss = 5\n",
    "counter = 0\n",
    "for epoch in range(600):\n",
    "    print(\"epoch is \",epoch)\n",
    "    trainSumEachEpoch = 0\n",
    "    trainchunkSum = 0\n",
    "    valSumEachEpoch = 0\n",
    "    valchunkSum = 0\n",
    "    for trainSong in trainloader:\n",
    "        chunkList = chunkListHelper(trainSong)\n",
    "        for chunk in chunkList:\n",
    "            #print(\"batch idx\",trainchunkSum)\n",
    "            #print(\"chunk is\",chunk.shape)\n",
    "            #print(\"train song is \",len(trainSong))\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            #print(\"target is\", target)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            rnn.zero_grad()\n",
    "            predict = rnn(chunkTensor)\n",
    "            #print(\"target tensor is\",targetTensor)\n",
    "            #print(\"target shape is \",targetTensor.shape)\n",
    "            #print(\"output shape is \",predict.shape)\n",
    "            targetTensor = targetTensor.type(torch.LongTensor)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            #print(\"batch is %s loss is %s\",(trainchunkSum,loss))\n",
    "            trainSumEachEpoch += loss\n",
    "            trainchunkSum += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        rnn.setHiddenCell(h0 = torch.zeros(layerNum,1,hiddenSize))\n",
    "        \n",
    "    \n",
    "    #save model\n",
    "    trainSumEachEpoch = trainSumEachEpoch / trainchunkSum\n",
    "    trainingLoss.append(trainSumEachEpoch.item())\n",
    "    savePath =\"./\"+\"%depoch%smodelRNN.pt\"%(epoch,\"test\")\n",
    "    torch.save(rnn, fileDir+\"/\"+savePath)\n",
    "    print(\"training error is\",trainSumEachEpoch.item())\n",
    "    print(\"model saved\")\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for valSong in valList:\n",
    "            chunkList = chunkListHelper(valSong)\n",
    "            for chunk in chunkList:\n",
    "                target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "                target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "                target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "                target = np.squeeze(target, axis=1)\n",
    "                target = np.argmax(target,axis = 1)\n",
    "                chunkTensor = torch.from_numpy(chunk)\n",
    "                targetTensor = torch.from_numpy(target)\n",
    "                targetTensor = targetTensor.long()\n",
    "                chunkTensor = chunkTensor.to(computing_device)\n",
    "                targetTensor = targetTensor.to(computing_device)\n",
    "                predict = rnn(chunkTensor)\n",
    "                loss = loss_function(predict,targetTensor)\n",
    "                valSumEachEpoch+=loss\n",
    "                valchunkSum+=1\n",
    "\n",
    "        valSumEachEpoch = valSumEachEpoch / valchunkSum\n",
    "        validationLoss.append(valSumEachEpoch.item())\n",
    "        print(\"validation error is\", valSumEachEpoch.item())\n",
    "        \n",
    "        # implement early stop\n",
    "        if valSumEachEpoch.item() >= prevLoss:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "        if counter > earlyStopPatience:\n",
    "            print(\"stop training for exceeding patience \")\n",
    "            break\n",
    "        #print(\"epoch is )\n",
    "        prevLoss = valSumEachEpoch.item()\n",
    "        #print(\"trainging in epoch end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicName = \"/experimentMusic.txt\"\n",
    "modelPath = \"15epochbestmodel.pt\"\n",
    "fileReader = open(fileDir+musicName)\n",
    "characterList = []\n",
    "hiddenState = []\n",
    "for line in fileReader:\n",
    "    for char in line:\n",
    "        characterList.append(char)\n",
    "        \n",
    "Lstm = torch.load(modelPath)\n",
    "softmax = nn.Softmax()\n",
    "with torch.no_grad():\n",
    "    for eachChar in characterList:\n",
    "        input = oneHotDict[eachChar]\n",
    "        input = torch.from_numpy(input)\n",
    "        inputTensor = torch.empty(1,1,96)\n",
    "        inputTensor[0][0] = input\n",
    "        inputTensor = inputTensor.to(computing_device)\n",
    "        out = Lstm(inputTensor)\n",
    "        newweightlist = []\n",
    "        weight = list(Lstm.lstm.parameters())\n",
    "        for eachweight in weight:\n",
    "            temp = eachweight.data\n",
    "            newweightlist.append(softmax(temp))\n",
    "        hiddenState.append(newweightlist)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetables = [\"cucumber\", \"tomato\", \"lettuce\", \"asparagus\",\n",
    "              \"potato\", \"wheat\", \"barley\"]\n",
    "farmers = [\"Farmer Joe\", \"Upland Bros.\", \"Smith Gardening\",\n",
    "           \"Agrifun\", \"Organiculture\", \"BioGoods Ltd.\", \"Cornylee Corp.\"]\n",
    "\n",
    "harvest = np.array([[0.8, 2.4, 2.5, 3.9, 0.0, 4.0, 0.0],\n",
    "                    [2.4, 0.0, 4.0, 1.0, 2.7, 0.0, 0.0],\n",
    "                    [1.1, 2.4, 0.8, 4.3, 1.9, 4.4, 0.0],\n",
    "                    [0.6, 0.0, 0.3, 0.0, 3.1, 0.0, 0.0],\n",
    "                    [0.7, 1.7, 0.6, 2.6, 2.2, 6.2, 0.0],\n",
    "                    [1.3, 1.2, 0.0, 0.0, 0.0, 3.2, 5.1],\n",
    "                    [0.1, 2.0, 0.0, 1.4, 0.0, 1.9, 6.3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data,ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (N, M).\n",
    "    row_labels\n",
    "        A list or array of length N with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length M with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A list or array of two color specifications.  The first is used for\n",
    "        values below a threshold, the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "im, cbar = heatmap(harvest, vegetables, farmers, ax=ax,\n",
    "                   cmap=\"YlGn\", cbarlabel=\"harvest [t/year]\")\n",
    "texts = annotate_heatmap(im, valfmt=\"{x:.1f} t\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
