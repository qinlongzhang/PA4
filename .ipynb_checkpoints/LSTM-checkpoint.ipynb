{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from readfile import readfile\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDir = \"/home/qiz103/PA4\"\n",
    "#torch.manual_seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainList(filePath,oneHotDict):\n",
    "    songList = []\n",
    "    f = open(filePath)\n",
    "    for line in f:\n",
    "        if line == \"<start>\\n\":\n",
    "            song = []\n",
    "            song.append(oneHotDict[\"~~\"])\n",
    "        elif line == \"<end>\\n\":\n",
    "            song.append(oneHotDict[\"~~~\"])\n",
    "            songList.append(song)\n",
    "        else: \n",
    "            for char in line:\n",
    "                song.append(oneHotDict[char])\n",
    "                \n",
    "    return songList\n",
    "            \n",
    "def chunkListHelper(song):\n",
    "    chunkList = []\n",
    "    for idx in range(math.floor(len(song) / 100)):\n",
    "        chunk = song[(idx*100):((idx + 1)*100)]\n",
    "        if len(chunk)!= 0:\n",
    "            chunkList.append(chunk)\n",
    "    chunk = song[(math.floor(len(song) / 100)*100):len(song)]\n",
    "    if len(chunk)!= 0:\n",
    "        chunkList.append(chunk)\n",
    "    \n",
    "    resultList = []\n",
    "    for chunk in chunkList:\n",
    "        result = np.empty([len(chunk),1,96])\n",
    "        for seqIdx,seq in enumerate(chunk):\n",
    "            result[seqIdx][0] = seq\n",
    "        \n",
    "        resultList.append(result)\n",
    "            \n",
    "            \n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "<class 'numpy.ndarray'>\n",
      "96\n",
      "what is the type of note float32\n"
     ]
    }
   ],
   "source": [
    "filePath = fileDir + \"/train.txt\"\n",
    "valPath = fileDir + \"/val.txt\"\n",
    "testPath = fileDir + \"/test.txt\"\n",
    "fileReader = readfile()\n",
    "oneHotDict = fileReader.returnTheDict(filePath)\n",
    "print(len(oneHotDict))\n",
    "songList = generateTrainList(filePath,oneHotDict)\n",
    "print(type(songList[0][0]))\n",
    "print(len(songList[0][0]))\n",
    "print(\"what is the type of note\", songList[0][0].dtype)\n",
    "valList = generateTrainList(valPath,oneHotDict)\n",
    "testList = generateTrainList(testPath,oneHotDict)\n",
    "random.shuffle(songList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCustom(data.Dataset):\n",
    "    def __init__(self,songList):\n",
    "        self.songList = songList\n",
    "    def __len__(self):\n",
    "        return len(self.songList)\n",
    "    def __getitem__(self,index):\n",
    "        return self.songList[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing part of Dataset generator \n",
    "datasetCustom = DatasetCustom(songList)\n",
    "trainloader = torch.utils.data.DataLoader(datasetCustom, batch_size=1,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMcustomize(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,layerNum,dropout):\n",
    "        super(LSTMcustomize,self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size = inputSize,hidden_size = hiddenSize,num_layers = layerNum,dropout = dropout)\n",
    "        self.to_output = nn.Linear(hiddenSize,inputSize)\n",
    "        #self.to_act = nn.Softmax()\n",
    "        self.h0 = torch.zeros(layerNum,1,hiddenSize)\n",
    "        self.c0 = torch.zeros(layerNum,1,hiddenSize)\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.inputSize = inputSize\n",
    "        self.layerNum = layerNum\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        self.h0 = self.h0.requires_grad_().to(computing_device)\n",
    "        self.c0 = self.c0.requires_grad_().to(computing_device)\n",
    "        #print(\"input is cuda\",input.is_cuda)\n",
    "        #print(\"is ho  cuda\",self.h0.is_cuda)\n",
    "        #print(\"is c0 cuda\", self.c0.is_cuda)\n",
    "        self.h0 = self.h0.float()\n",
    "        self.c0 = self.c0.float()\n",
    "        input = input.float()\n",
    "        #print(\"type check\", input.dtype)\n",
    "        #print(\"type of h0 is \",self.h0.dtype)\n",
    "        #print(\"type of c0 is \",self.c0.dtype)\n",
    "        #self.h0.double()\n",
    "        #self.c0.double()\n",
    "        #input.double()\n",
    "        output,(hn,cn) = self.lstm(input,(self.h0.detach(),self.c0.detach()))\n",
    "        self.h0 = hn\n",
    "        self.c0 = cn\n",
    "        linearOut = self.to_output(output.view(-1,self.hiddenSize))\n",
    "        #result = self.to_act(linearOut)\n",
    "        return linearOut\n",
    "    \n",
    "    def setHiddenCell(self,h0,c0):\n",
    "        self.h0 = h0\n",
    "        self.c0 = c0\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMcustomize(\n",
      "  (lstm): LSTM(96, 175)\n",
      "  (to_output): Linear(in_features=175, out_features=96, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layerNum = 1\n",
    "hiddenSize = 175\n",
    "#lstm = LSTMcustomize(inputSize = 95 ,hiddenSize = 100,layerNum = 1,dropout = 0)\n",
    "lstm = LSTMcustomize(inputSize = 96 ,hiddenSize = hiddenSize,layerNum = layerNum,dropout = 0).to(computing_device)\n",
    "print(lstm)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lstm.parameters(),lr = 0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is  0\n",
      "training error is 3.460869789123535\n",
      "model saved\n",
      "validation error is 3.3191981315612793\n",
      "epoch is  1\n",
      "training error is 2.9074714183807373\n",
      "model saved\n",
      "validation error is 2.85705304145813\n",
      "epoch is  2\n",
      "training error is 2.4744882583618164\n",
      "model saved\n",
      "validation error is 2.489494800567627\n",
      "epoch is  3\n",
      "training error is 2.1956839561462402\n",
      "model saved\n",
      "validation error is 2.318507432937622\n",
      "epoch is  4\n",
      "training error is 2.0272839069366455\n",
      "model saved\n",
      "validation error is 2.2244558334350586\n",
      "epoch is  5\n",
      "training error is 1.896042823791504\n",
      "model saved\n",
      "validation error is 2.1325995922088623\n",
      "epoch is  6\n",
      "training error is 1.8052690029144287\n",
      "model saved\n",
      "validation error is 2.0278878211975098\n",
      "epoch is  7\n",
      "training error is 1.7436845302581787\n",
      "model saved\n",
      "validation error is 2.056854486465454\n",
      "epoch is  8\n",
      "training error is 1.6894210577011108\n",
      "model saved\n",
      "validation error is 1.989040493965149\n",
      "epoch is  9\n",
      "training error is 1.638279914855957\n",
      "model saved\n",
      "validation error is 1.936734676361084\n",
      "epoch is  10\n",
      "training error is 1.6131376028060913\n",
      "model saved\n",
      "validation error is 1.9346513748168945\n",
      "epoch is  11\n",
      "training error is 1.5681718587875366\n",
      "model saved\n",
      "validation error is 1.905491828918457\n",
      "epoch is  12\n",
      "training error is 1.5353035926818848\n",
      "model saved\n",
      "validation error is 1.8854079246520996\n",
      "epoch is  13\n",
      "training error is 1.5108495950698853\n",
      "model saved\n",
      "validation error is 1.8348387479782104\n",
      "epoch is  14\n",
      "training error is 1.4821776151657104\n",
      "model saved\n",
      "validation error is 1.8717470169067383\n",
      "epoch is  15\n",
      "training error is 1.458892822265625\n",
      "model saved\n",
      "validation error is 1.808215618133545\n",
      "epoch is  16\n",
      "training error is 1.4383634328842163\n",
      "model saved\n",
      "validation error is 1.8330631256103516\n",
      "epoch is  17\n",
      "training error is 1.418257474899292\n",
      "model saved\n",
      "validation error is 1.8239027261734009\n",
      "epoch is  18\n",
      "training error is 1.4100548028945923\n",
      "model saved\n",
      "validation error is 1.806549310684204\n",
      "epoch is  19\n",
      "training error is 1.384229063987732\n",
      "model saved\n",
      "validation error is 1.810706615447998\n",
      "epoch is  20\n",
      "training error is 1.3686400651931763\n",
      "model saved\n",
      "validation error is 1.7896023988723755\n",
      "epoch is  21\n",
      "training error is 1.353436827659607\n",
      "model saved\n",
      "validation error is 1.7770135402679443\n",
      "epoch is  22\n",
      "training error is 1.3408024311065674\n",
      "model saved\n",
      "validation error is 1.759055733680725\n",
      "epoch is  23\n",
      "training error is 1.3318071365356445\n",
      "model saved\n",
      "validation error is 1.7765699625015259\n",
      "epoch is  24\n",
      "training error is 1.3102978467941284\n",
      "model saved\n",
      "validation error is 1.7884187698364258\n",
      "epoch is  25\n",
      "training error is 1.302321195602417\n",
      "model saved\n",
      "validation error is 1.7721822261810303\n",
      "epoch is  26\n",
      "training error is 1.2870746850967407\n",
      "model saved\n",
      "validation error is 1.7662245035171509\n",
      "epoch is  27\n",
      "training error is 1.2789798974990845\n",
      "model saved\n",
      "validation error is 1.7679675817489624\n",
      "epoch is  28\n",
      "training error is 1.2673289775848389\n",
      "model saved\n",
      "validation error is 1.7723838090896606\n",
      "epoch is  29\n",
      "training error is 1.2573612928390503\n",
      "model saved\n",
      "validation error is 1.7558178901672363\n",
      "epoch is  30\n",
      "training error is 1.251530408859253\n",
      "model saved\n",
      "validation error is 1.7688614130020142\n",
      "epoch is  31\n",
      "training error is 1.2390613555908203\n",
      "model saved\n",
      "validation error is 1.774263620376587\n",
      "epoch is  32\n",
      "training error is 1.227337121963501\n",
      "model saved\n",
      "validation error is 1.762492060661316\n",
      "epoch is  33\n",
      "training error is 1.2199536561965942\n",
      "model saved\n",
      "validation error is 1.7632675170898438\n",
      "epoch is  34\n",
      "training error is 1.2105048894882202\n",
      "model saved\n",
      "validation error is 1.7986506223678589\n",
      "epoch is  35\n",
      "training error is 1.2020831108093262\n",
      "model saved\n",
      "validation error is 1.7574797868728638\n",
      "epoch is  36\n",
      "training error is 1.1954662799835205\n",
      "model saved\n",
      "validation error is 1.7975822687149048\n",
      "epoch is  37\n",
      "training error is 1.2205923795700073\n",
      "model saved\n",
      "validation error is 1.8290221691131592\n",
      "epoch is  38\n",
      "training error is 1.2117958068847656\n",
      "model saved\n",
      "validation error is 1.7866063117980957\n",
      "epoch is  39\n",
      "training error is 1.1792821884155273\n",
      "model saved\n",
      "validation error is 1.7798957824707031\n",
      "epoch is  40\n",
      "training error is 1.1658296585083008\n",
      "model saved\n",
      "validation error is 1.7593973875045776\n",
      "epoch is  41\n",
      "training error is 1.1567450761795044\n",
      "model saved\n",
      "validation error is 1.775057077407837\n",
      "epoch is  42\n",
      "training error is 1.1490682363510132\n",
      "model saved\n",
      "validation error is 1.7554017305374146\n",
      "epoch is  43\n",
      "training error is 1.1444755792617798\n",
      "model saved\n",
      "validation error is 1.8176497220993042\n",
      "epoch is  44\n",
      "training error is 1.1462857723236084\n",
      "model saved\n",
      "validation error is 1.7973051071166992\n",
      "epoch is  45\n",
      "training error is 1.1338608264923096\n",
      "model saved\n",
      "validation error is 1.774682641029358\n",
      "epoch is  46\n",
      "training error is 1.1239010095596313\n",
      "model saved\n",
      "validation error is 1.799109935760498\n",
      "epoch is  47\n",
      "training error is 1.115356683731079\n",
      "model saved\n",
      "validation error is 1.8012653589248657\n",
      "epoch is  48\n",
      "training error is 1.114487886428833\n",
      "model saved\n",
      "validation error is 1.809523105621338\n",
      "epoch is  49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c5a199f69615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtrainSumEachEpoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtrainchunkSum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "trainingLoss = []\n",
    "validationLoss = []\n",
    "testLoss = []\n",
    "earlyStopPatience = 5\n",
    "prevLoss = 5\n",
    "counter = 0\n",
    "for epoch in range(600):\n",
    "    print(\"epoch is \",epoch)\n",
    "    trainSumEachEpoch = 0\n",
    "    trainchunkSum = 0\n",
    "    valSumEachEpoch = 0\n",
    "    valchunkSum = 0\n",
    "    for trainSong in trainloader:\n",
    "        chunkList = chunkListHelper(trainSong)\n",
    "        for chunk in chunkList:\n",
    "            #print(\"batch idx\",trainchunkSum)\n",
    "            #print(\"chunk is\",chunk.shape)\n",
    "            #print(\"train song is \",len(trainSong))\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            #print(\"target is\", target)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            lstm.zero_grad()\n",
    "            predict = lstm(chunkTensor)\n",
    "            #print(\"target tensor is\",targetTensor)\n",
    "            #print(\"target shape is \",targetTensor.shape)\n",
    "            #print(\"output shape is \",predict.shape)\n",
    "            targetTensor = targetTensor.type(torch.LongTensor)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            #print(\"batch is %s loss is %s\",(trainchunkSum,loss))\n",
    "            trainSumEachEpoch += loss\n",
    "            trainchunkSum += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        lstm.setHiddenCell(h0 = torch.zeros(layerNum,1,hiddenSize),c0 = torch.zeros(layerNum,1,hiddenSize))\n",
    "        \n",
    "    \n",
    "    #save model\n",
    "    trainSumEachEpoch = trainSumEachEpoch / trainchunkSum\n",
    "    trainingLoss.append(trainSumEachEpoch.item())\n",
    "    savePath =\"./\"+\"%depoch%smodel.pt\"%(epoch,\"best\")\n",
    "    torch.save(lstm, fileDir+\"/\"+savePath)\n",
    "    print(\"training error is\",trainSumEachEpoch.item())\n",
    "    print(\"model saved\")\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for valSong in valList:\n",
    "            chunkList = chunkListHelper(valSong)\n",
    "            for chunk in chunkList:\n",
    "                target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "                target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "                target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "                target = np.squeeze(target, axis=1)\n",
    "                target = np.argmax(target,axis = 1)\n",
    "                chunkTensor = torch.from_numpy(chunk)\n",
    "                targetTensor = torch.from_numpy(target)\n",
    "                targetTensor = targetTensor.long()\n",
    "                chunkTensor = chunkTensor.to(computing_device)\n",
    "                targetTensor = targetTensor.to(computing_device)\n",
    "                predict = lstm(chunkTensor)\n",
    "                loss = loss_function(predict,targetTensor)\n",
    "                valSumEachEpoch+=loss\n",
    "                valchunkSum+=1\n",
    "\n",
    "        valSumEachEpoch = valSumEachEpoch / valchunkSum\n",
    "        validationLoss.append(valSumEachEpoch.item())\n",
    "        print(\"validation error is\", valSumEachEpoch.item())\n",
    "        \n",
    "        # implement early stop\n",
    "        if valSumEachEpoch.item() >= prevLoss:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "        if counter > earlyStopPatience:\n",
    "            print(\"stop training for exceeding patience \")\n",
    "            break\n",
    "        #print(\"epoch is )\n",
    "        prevLoss = valSumEachEpoch.item()\n",
    "        #print(\"trainging in epoch end\")\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss is  1.67764413356781\n",
      "test loss is  1.7092877626419067\n"
     ]
    }
   ],
   "source": [
    "#report metrics\n",
    "modelPath = \"15epochbestmodel.pt\"\n",
    "lstm = torch.load(modelPath)\n",
    "valchunkSum = 0\n",
    "valSumEachEpoch = 0\n",
    "with torch.no_grad():\n",
    "    for valSong in valList:\n",
    "        chunkList = chunkListHelper(valSong)\n",
    "        for chunk in chunkList:\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.long()\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            predict = lstm(chunkTensor)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            valSumEachEpoch+=loss\n",
    "            valchunkSum+=1\n",
    "\n",
    "    valSumEachEpoch = valSumEachEpoch / valchunkSum\n",
    "    print(\"validation loss is \",valSumEachEpoch.item())\n",
    "\n",
    "testchunkSum = 0\n",
    "testSumEachEpoch = 0\n",
    "with torch.no_grad():\n",
    "    for testSong in testList:\n",
    "        chunkList = chunkListHelper(testSong)\n",
    "        for chunk in chunkList:\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.long()\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            predict = lstm(chunkTensor)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            testSumEachEpoch+=loss\n",
    "            testchunkSum+=1\n",
    "\n",
    "    testSumEachEpoch = testSumEachEpoch / testchunkSum\n",
    "    print(\"test loss is \",testSumEachEpoch.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training validation loss using SGD with learning rate 0.05, momentum 0.9, 200 neuron and 2 hidden layer')\n",
    "xAxis = np.arange(0,30)\n",
    "plt.plot(xAxis,trainingLoss[0:30],label = 'training loss')\n",
    "plt.plot(xAxis,validationLoss[0:30], label = 'validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(fileDir + \"test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char is  :\n",
      "char is  1\n",
      "char is  6\n",
      "char is  \n",
      "\n",
      "char is  T\n",
      "char is  :\n",
      "char is  L\n",
      "char is  a\n",
      "char is   \n",
      "char is  c\n",
      "char is  a\n",
      "char is  r\n",
      "char is  o\n",
      "char is  u\n",
      "char is  n\n",
      "char is  e\n",
      "char is   \n",
      "char is  d\n",
      "char is  e\n",
      "char is   \n",
      "char is  t\n",
      "char is  h\n",
      "char is  e\n",
      "char is   \n",
      "char is  T\n",
      "char is  h\n",
      "char is  e\n",
      "char is  \n",
      "\n",
      "char is  '\n",
      "char is  :\n",
      "char is  2\n",
      "char is  i\n",
      "char is  g\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  C\n",
      "char is  a\n",
      "char is  r\n",
      "char is  n\n",
      "char is  e\n",
      "char is  t\n",
      "char is   \n",
      "char is  d\n",
      "char is  u\n",
      "char is   \n",
      "char is  t\n",
      "char is  a\n",
      "char is  m\n",
      "char is  b\n",
      "char is  o\n",
      "char is  u\n",
      "char is  r\n",
      "char is  i\n",
      "char is  n\n",
      "char is  a\n",
      "char is  i\n",
      "char is  r\n",
      "char is  e\n",
      "char is   \n",
      "char is  G\n",
      "char is  i\n",
      "char is  n\n",
      "char is  a\n",
      "char is  s\n",
      "char is   \n",
      "char is  V\n",
      "char is  a\n",
      "char is   \n",
      "char is  g\n",
      "char is  a\n",
      "char is  l\n",
      "char is  o\n",
      "char is   \n",
      "char is  :\n",
      "char is   \n",
      "char is  1\n",
      "char is   \n",
      "char is  M\n",
      "char is  i\n",
      "char is  g\n",
      "char is  ~~~\n",
      "char is   \n",
      "char is  O\n",
      "char is  :\n",
      "char is  C\n",
      "char is  a\n",
      "char is  r\n",
      "char is  i\n",
      "char is  a\n",
      "char is  n\n",
      "char is  d\n",
      "char is  o\n",
      "char is  n\n",
      "char is  e\n",
      "char is  \n",
      "\n",
      "char is  Z\n",
      "char is  :\n",
      "char is  T\n",
      "char is  r\n",
      "char is  a\n",
      "char is  n\n",
      "char is  s\n",
      "char is  c\n",
      "char is  r\n",
      "char is  i\n",
      "char is  t\n",
      "char is   \n",
      "char is  e\n",
      "char is  t\n",
      "char is  /\n",
      "char is  o\n",
      "char is  u\n",
      "char is   \n",
      "char is  c\n",
      "char is  o\n",
      "char is  r\n",
      "char is  r\n",
      "char is  i\n",
      "char is  g\n",
      "char is  ?\n",
      "char is   \n",
      "char is  p\n",
      "char is  a\n",
      "char is  r\n",
      "char is   \n",
      "char is  M\n",
      "char is  i\n",
      "char is  c\n",
      "char is  h\n",
      "char is  e\n",
      "char is  l\n",
      "char is   \n",
      "char is  B\n",
      "char is  E\n",
      "char is  L\n",
      "char is  L\n",
      "char is  O\n",
      "char is  N\n",
      "char is   \n",
      "char is  -\n",
      "char is   \n",
      "char is  2\n",
      "char is  0\n",
      "char is  0\n",
      "char is  5\n",
      "char is  -\n",
      "char is  0\n",
      "char is  7\n",
      "char is  -\n",
      "char is  1\n",
      "char is  4\n",
      "char is  \n",
      "\n",
      "char is  Z\n",
      "char is  :\n",
      "char is  P\n",
      "char is  o\n",
      "char is  u\n",
      "char is  r\n",
      "char is   \n",
      "char is  t\n",
      "char is  o\n",
      "char is  u\n",
      "char is  t\n",
      "char is  e\n",
      "char is   \n",
      "char is  o\n",
      "char is  b\n",
      "char is  s\n",
      "char is  e\n",
      "char is  r\n",
      "char is  v\n",
      "char is  a\n",
      "char is  t\n",
      "char is  i\n",
      "char is  o\n",
      "char is  n\n",
      "char is   \n",
      "char is  m\n",
      "char is  a\n",
      "char is  i\n",
      "char is  l\n",
      "char is  t\n",
      "char is  o\n",
      "char is  :\n",
      "char is  g\n",
      "char is  a\n",
      "char is  l\n",
      "char is  o\n",
      "char is  u\n",
      "char is  v\n",
      "char is  i\n",
      "char is  e\n",
      "char is  l\n",
      "char is  l\n",
      "char is  e\n",
      "char is  @\n",
      "char is  f\n",
      "char is  r\n",
      "char is  e\n",
      "char is  e\n",
      "char is  .\n",
      "char is  f\n",
      "char is  r\n",
      "char is  \n",
      "\n",
      "char is  M\n",
      "char is  :\n",
      "char is  2\n",
      "char is  /\n",
      "char is  4\n",
      "char is  \n",
      "\n",
      "char is  L\n",
      "char is  :\n",
      "char is  1\n",
      "char is  /\n",
      "char is  8\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  1\n",
      "char is  /\n",
      "char is  4\n",
      "char is  =\n",
      "char is  1\n",
      "char is  0\n",
      "char is  0\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  1\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  1\n",
      "char is  6\n",
      "char is  /\n",
      "char is  8\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  1\n",
      "char is  /\n",
      "char is  8\n",
      "char is  =\n",
      "char is  1\n",
      "char is  0\n",
      "char is  0\n",
      "char is  \n",
      "\n",
      "char is  ~~\n",
      "char is  :\n",
      "char is  1\n",
      "char is  \n",
      "\n",
      "char is  G\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n",
      "char is   \n",
      "char is  |\n",
      "char is   \n",
      "char is  B\n",
      "char is  2\n",
      "char is  B\n",
      "char is  2\n"
     ]
    }
   ],
   "source": [
    "musicName = \"/experimentMusic.txt\"\n",
    "if os.path.exists(fileDir+musicName):\n",
    "    os.remove(fileDir+musicName)\n",
    "f = open(fileDir+musicName,\"w\")\n",
    "modelPath = \"10epochbestmodel.pt\"\n",
    "primeLength = 1\n",
    "songIndex = 18\n",
    "musicString = \"\"\n",
    "temperature = 1\n",
    "length = 400\n",
    "prime = songList[songIndex][0:primeLength]\n",
    "for idx in range(primeLength):\n",
    "    char = fileReader.noteList[np.argmax(songList[songIndex][idx])]\n",
    "    if char == \"~~\":\n",
    "        char = \"<start>\\n\"\n",
    "    \n",
    "    if char == \"~~~\":\n",
    "        char = \"<end>\\n\"\n",
    "        \n",
    "    musicString += char\n",
    "lstm = torch.load(modelPath)\n",
    "with torch.no_grad():\n",
    "    inputChunk = np.empty([len(prime),1,96])\n",
    "    for seqIdx,seq in enumerate(prime):\n",
    "        inputChunk[seqIdx][0] = seq\n",
    "    inputChunk = torch.from_numpy(inputChunk)\n",
    "    inputTensor = inputChunk.to(computing_device)\n",
    "    predict = lstm(inputTensor)\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    predict = softmax(predict / temperature)\n",
    "    generate = predict.cpu().detach().numpy()\n",
    "    \n",
    "    prevOutput = fileReader.noteList[np.argmax(generate[generate.shape[0]-1])]\n",
    "    nextInput = np.empty([1,1,96])\n",
    "    nextInput[0][0] = oneHotDict[prevOutput]\n",
    "    nextInput = torch.from_numpy(nextInput)\n",
    "    nextInput = nextInput.to(computing_device)\n",
    "    \n",
    "    for eachidx in range(length):\n",
    "        prevOutput = lstm(nextInput)\n",
    "        prevOutput = softmax(prevOutput / temperature)\n",
    "        prevOutput = prevOutput.cpu().detach().numpy()\n",
    "        prevOutput = fileReader.noteList[np.argmax(prevOutput[0])]\n",
    "        if prevOutput != \"!!!!\":\n",
    "            if prevOutput == \"~~\":\n",
    "                musicString +=\"\"\n",
    "            elif prevOutput == \"~~~\":\n",
    "                musicString +=\"\"\n",
    "            else:\n",
    "                musicString += prevOutput\n",
    "        \n",
    "        nextInput = np.empty([1,1,96])\n",
    "        nextInput[0][0] = oneHotDict[prevOutput]\n",
    "        nextInput = torch.from_numpy(nextInput)\n",
    "        nextInput = nextInput.to(computing_device)\n",
    "        \n",
    "        \n",
    "        print(\"char is \",prevOutput)\n",
    "                \n",
    "\n",
    "musicString += \"\\n\"\n",
    "musicString += \"<end>\\n\"\n",
    "f.write(musicString)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vaRNN(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,layerNum,dropout,nonlinearity):\n",
    "        super(vaRNN,self).__init__()\n",
    "        self.varnn = nn.RNN(input_size = inputSize,hidden_size = hiddenSize,num_layers = layerNum, nonlinearity = nonlinearity, dropout = dropout)\n",
    "        self.to_output = nn.Linear(hiddenSize,inputSize)\n",
    "        #self.to_act = nn.Softmax()\n",
    "        self.h0 = torch.zeros(layerNum,1,hiddenSize)\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.inputSize = inputSize\n",
    "        self.layerNum = layerNum\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        self.h0 = self.h0.requires_grad_().to(computing_device)\n",
    "        #print(\"input is cuda\",input.is_cuda)\n",
    "        #print(\"is ho  cuda\",self.h0.is_cuda)\n",
    "        #print(\"is c0 cuda\", self.c0.is_cuda)\n",
    "        self.h0 = self.h0.float()\n",
    "        input = input.float()\n",
    "        #print(\"type check\", input.dtype)\n",
    "        #print(\"type of h0 is \",self.h0.dtype)\n",
    "        #print(\"type of c0 is \",self.c0.dtype)\n",
    "        #self.h0.double()\n",
    "        #self.c0.double()\n",
    "        #input.double()\n",
    "        output,hn = self.varnn(input,self.h0.detach())\n",
    "        self.h0 = hn\n",
    "        linearOut = self.to_output(output.view(-1,self.hiddenSize))\n",
    "        #result = self.to_act(linearOut)\n",
    "        return linearOut\n",
    "    \n",
    "    def setHiddenCell(self,h0):\n",
    "        self.h0 = h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaRNN(\n",
      "  (varnn): RNN(96, 175)\n",
      "  (to_output): Linear(in_features=175, out_features=96, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "layerNum = 1\n",
    "hiddenSize = 175\n",
    "#lstm = LSTMcustomize(inputSize = 95 ,hiddenSize = 100,layerNum = 1,dropout = 0)\n",
    "rnn = vaRNN(inputSize = 96 ,hiddenSize = hiddenSize,layerNum = layerNum,nonlinearity = 'tanh',dropout = 0).to(computing_device)\n",
    "print(rnn)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(rnn.parameters(),lr = 0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type vaRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error is 2.989596128463745\n",
      "model saved\n",
      "validation error is 2.783297061920166\n",
      "epoch is  1\n",
      "training error is 3.0373141765594482\n",
      "model saved\n",
      "validation error is 3.3812804222106934\n",
      "epoch is  2\n",
      "training error is 2.9415104389190674\n",
      "model saved\n",
      "validation error is 3.00665545463562\n",
      "epoch is  3\n",
      "training error is 2.94016695022583\n",
      "model saved\n",
      "validation error is 2.9932363033294678\n",
      "epoch is  4\n",
      "training error is 2.86741304397583\n",
      "model saved\n",
      "validation error is 3.026684284210205\n",
      "epoch is  5\n",
      "training error is 2.833221435546875\n",
      "model saved\n",
      "validation error is 3.0008902549743652\n",
      "epoch is  6\n",
      "training error is 2.760730504989624\n",
      "model saved\n",
      "validation error is 3.3969547748565674\n",
      "epoch is  7\n"
     ]
    }
   ],
   "source": [
    "trainingLoss = []\n",
    "validationLoss = []\n",
    "testLoss = []\n",
    "earlyStopPatience = 5\n",
    "prevLoss = 5\n",
    "counter = 0\n",
    "for epoch in range(600):\n",
    "    print(\"epoch is \",epoch)\n",
    "    trainSumEachEpoch = 0\n",
    "    trainchunkSum = 0\n",
    "    valSumEachEpoch = 0\n",
    "    valchunkSum = 0\n",
    "    for trainSong in trainloader:\n",
    "        chunkList = chunkListHelper(trainSong)\n",
    "        for chunk in chunkList:\n",
    "            #print(\"batch idx\",trainchunkSum)\n",
    "            #print(\"chunk is\",chunk.shape)\n",
    "            #print(\"train song is \",len(trainSong))\n",
    "            target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "            target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "            target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "            target = np.squeeze(target, axis=1)\n",
    "            target = np.argmax(target,axis = 1)\n",
    "            #print(\"target is\", target)\n",
    "            chunkTensor = torch.from_numpy(chunk)\n",
    "            chunkTensor = chunkTensor.to(computing_device)\n",
    "            targetTensor = torch.from_numpy(target)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            rnn.zero_grad()\n",
    "            predict = rnn(chunkTensor)\n",
    "            #print(\"target tensor is\",targetTensor)\n",
    "            #print(\"target shape is \",targetTensor.shape)\n",
    "            #print(\"output shape is \",predict.shape)\n",
    "            targetTensor = targetTensor.type(torch.LongTensor)\n",
    "            targetTensor = targetTensor.to(computing_device)\n",
    "            loss = loss_function(predict,targetTensor)\n",
    "            #print(\"batch is %s loss is %s\",(trainchunkSum,loss))\n",
    "            trainSumEachEpoch += loss\n",
    "            trainchunkSum += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        rnn.setHiddenCell(h0 = torch.zeros(layerNum,1,hiddenSize))\n",
    "        \n",
    "    \n",
    "    #save model\n",
    "    trainSumEachEpoch = trainSumEachEpoch / trainchunkSum\n",
    "    trainingLoss.append(trainSumEachEpoch.item())\n",
    "    savePath =\"./\"+\"%depoch%smodelRNN.pt\"%(epoch,\"test\")\n",
    "    torch.save(rnn, fileDir+\"/\"+savePath)\n",
    "    print(\"training error is\",trainSumEachEpoch.item())\n",
    "    print(\"model saved\")\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for valSong in valList:\n",
    "            chunkList = chunkListHelper(valSong)\n",
    "            for chunk in chunkList:\n",
    "                target = np.empty([chunk.shape[0],chunk.shape[1],chunk.shape[2]])\n",
    "                target[0:(chunk.shape[0]-1),0,:] = chunk[1:chunk.shape[0],0,:]\n",
    "                target[(chunk.shape[0]-1):0,:] = oneHotDict[\"!!!!\"]\n",
    "                target = np.squeeze(target, axis=1)\n",
    "                target = np.argmax(target,axis = 1)\n",
    "                chunkTensor = torch.from_numpy(chunk)\n",
    "                targetTensor = torch.from_numpy(target)\n",
    "                targetTensor = targetTensor.long()\n",
    "                chunkTensor = chunkTensor.to(computing_device)\n",
    "                targetTensor = targetTensor.to(computing_device)\n",
    "                predict = rnn(chunkTensor)\n",
    "                loss = loss_function(predict,targetTensor)\n",
    "                valSumEachEpoch+=loss\n",
    "                valchunkSum+=1\n",
    "\n",
    "        valSumEachEpoch = valSumEachEpoch / valchunkSum\n",
    "        validationLoss.append(valSumEachEpoch.item())\n",
    "        print(\"validation error is\", valSumEachEpoch.item())\n",
    "        \n",
    "        # implement early stop\n",
    "        if valSumEachEpoch.item() >= prevLoss:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "\n",
    "        if counter > earlyStopPatience:\n",
    "            print(\"stop training for exceeding patience \")\n",
    "            break\n",
    "        #print(\"epoch is )\n",
    "        prevLoss = valSumEachEpoch.item()\n",
    "        #print(\"trainging in epoch end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
